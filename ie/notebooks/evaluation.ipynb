{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER\n",
    "不让llm去确认位置，我自己用算法后期加上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL REPORT INDICATION : ___ F with cough / / Cough TECHNIQUE : PA and lateral views of the chest . COMPARISON : None . FINDINGS : The lungs are clear without focal consolidation , , or edema . The cardiomediastinal silhouette is within normal limits . No acute osseous abnormalities . IMPRESSION : No acute cardiopulmonary process .\n",
      "{'1': {'tokens': 'lungs', 'label': 'ANAT-DP', 'start_ix': 28, 'end_ix': 28, 'relations': []}, '2': {'tokens': 'clear', 'label': 'OBS-DP', 'start_ix': 30, 'end_ix': 30, 'relations': [['located_at', '1']]}, '3': {'tokens': 'focal', 'label': 'OBS-DA', 'start_ix': 32, 'end_ix': 32, 'relations': [['modify', '4']]}, '4': {'tokens': 'consolidation', 'label': 'OBS-DA', 'start_ix': 33, 'end_ix': 33, 'relations': [['located_at', '1']]}, '5': {'tokens': 'edema', 'label': 'OBS-DA', 'start_ix': 37, 'end_ix': 37, 'relations': [['located_at', '1']]}, '6': {'tokens': 'cardiomediastinal', 'label': 'ANAT-DP', 'start_ix': 40, 'end_ix': 40, 'relations': []}, '7': {'tokens': 'silhouette', 'label': 'ANAT-DP', 'start_ix': 41, 'end_ix': 41, 'relations': [['modify', '6']]}, '8': {'tokens': 'within', 'label': 'OBS-DP', 'start_ix': 43, 'end_ix': 43, 'relations': [['modify', '9']]}, '9': {'tokens': 'normal', 'label': 'OBS-DP', 'start_ix': 44, 'end_ix': 44, 'relations': [['located_at', '6']]}, '10': {'tokens': 'limits', 'label': 'OBS-DP', 'start_ix': 45, 'end_ix': 45, 'relations': [['modify', '9']]}, '11': {'tokens': 'acute', 'label': 'OBS-DA', 'start_ix': 48, 'end_ix': 48, 'relations': [['modify', '13']]}, '12': {'tokens': 'osseous', 'label': 'ANAT-DP', 'start_ix': 49, 'end_ix': 49, 'relations': []}, '13': {'tokens': 'abnormalities', 'label': 'OBS-DA', 'start_ix': 50, 'end_ix': 50, 'relations': [['located_at', '12']]}, '14': {'tokens': 'acute', 'label': 'OBS-DA', 'start_ix': 55, 'end_ix': 55, 'relations': [['modify', '16']]}, '15': {'tokens': 'cardiopulmonary', 'label': 'ANAT-DP', 'start_ix': 56, 'end_ix': 56, 'relations': []}, '16': {'tokens': 'process', 'label': 'OBS-DA', 'start_ix': 57, 'end_ix': 57, 'relations': [['located_at', '15']]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lungs': 'ANAT-DP',\n",
       " 'clear': 'OBS-DP',\n",
       " 'focal': 'OBS-DA',\n",
       " 'consolidation': 'OBS-DA',\n",
       " 'edema': 'OBS-DA',\n",
       " 'cardiomediastinal': 'ANAT-DP',\n",
       " 'silhouette': 'ANAT-DP',\n",
       " 'within': 'OBS-DP',\n",
       " 'normal': 'OBS-DP',\n",
       " 'limits': 'OBS-DP',\n",
       " 'acute': 'OBS-DA',\n",
       " 'osseous': 'ANAT-DP',\n",
       " 'abnormalities': 'OBS-DA',\n",
       " 'cardiopulmonary': 'ANAT-DP',\n",
       " 'process': 'OBS-DA'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/hbchen/Projects/MedKGC/resource/radgraph/test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "json_result = None\n",
    "text = None\n",
    "\n",
    "index = 0\n",
    "for key, value in data.items():\n",
    "    json_result = value['labeler_1']['entities']\n",
    "    text = value['text']\n",
    "\n",
    "    break\n",
    "    index += 1\n",
    "    \n",
    "    if index == 4:\n",
    "        break\n",
    "\n",
    "print(text)\n",
    "\n",
    "def tuple_from_radgraph(json_result):\n",
    "    result = {}\n",
    "    for key, value in json_result.items():\n",
    "        result[value['tokens']] = value['label']\n",
    "    return result\n",
    "\n",
    "print(json_result)\n",
    "result = tuple_from_radgraph(json_result)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 10:52:21 urllib3.connectionpool DEBUG: Starting new HTTP connection (1): ollama.corinth.informatik.rwth-aachen.de:80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL REPORT INDICATION : ___ F with cough / / Cough TECHNIQUE : PA and lateral views of the chest . COMPARISON : None . FINDINGS : The lungs are clear without focal consolidation , , or edema . The cardiomediastinal silhouette is within normal limits . No acute osseous abnormalities . IMPRESSION : No acute cardiopulmonary process .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 10:52:25 urllib3.connectionpool DEBUG: http://ollama.corinth.informatik.rwth-aachen.de:80 \"POST /api/chat HTTP/1.1\" 200 1263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'1': {'tokens': 'lungs', 'label': 'ANAT-DP'},\n",
       " '2': {'tokens': 'clear', 'label': 'OBS-DP'},\n",
       " '3': {'tokens': 'focal', 'label': 'OBS-DA'},\n",
       " '4': {'tokens': 'consolidation', 'label': 'OBS-DA'},\n",
       " '5': {'tokens': 'edema', 'label': 'OBS-DA'},\n",
       " '6': {'tokens': 'cardiomediastinal', 'label': 'ANAT-DP'},\n",
       " '7': {'tokens': 'silhouette', 'label': 'ANAT-DP'},\n",
       " '8': {'tokens': 'within', 'label': 'OBS-DP'},\n",
       " '9': {'tokens': 'normal', 'label': 'OBS-DP'},\n",
       " '10': {'tokens': 'limits', 'label': 'OBS-DA'},\n",
       " '11': {'tokens': 'acute', 'label': 'OBS-DA'},\n",
       " '12': {'tokens': 'osseous', 'label': 'ANAT-DP'},\n",
       " '13': {'tokens': 'abnormalities', 'label': 'OBS-DA'},\n",
       " '14': {'tokens': 'cardiopulmonary', 'label': 'ANAT-DP'},\n",
       " '15': {'tokens': 'process', 'label': 'OBS-DA'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Create a session object\n",
    "session = requests.Session()\n",
    "\n",
    "def extract_entities(text):\n",
    "  url = 'http://ollama.corinth.informatik.rwth-aachen.de/api/chat'\n",
    "\n",
    "  data = {\n",
    "    \"model\": \"llama3.1:8b\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": '''You are a computer scientist and radiology expert specializing in named entity recognition (NER) and relation extraction. Your task is to extract entities from the provided radiology report text and classify them into one of the following labels: ANAT-DP, OBS-DP, OBS-U, OBS-DA.\n",
    "\n",
    "Here are some examples of how entities should be extracted and classified:\n",
    "\n",
    "Example 1:\n",
    "Input text:\n",
    "\"FINAL REPORT INDICATION: ___ F with cough / / Cough TECHNIQUE: PA and lateral views of the chest. COMPARISON: None. FINDINGS: The lungs are clear without focal consolidation, or edema. The cardiomediastinal silhouette is within normal limits. No acute osseous abnormalities. IMPRESSION: No acute cardiopulmonary process.\"\n",
    "\n",
    "Extracted entities:\n",
    "{\n",
    " 'lungs': 'ANAT-DP',\n",
    " 'clear': 'OBS-DP',\n",
    " 'focal': 'OBS-DA',\n",
    " 'consolidation': 'OBS-DA',\n",
    " 'edema': 'OBS-DA',\n",
    " 'cardiomediastinal': 'ANAT-DP',\n",
    " 'silhouette': 'ANAT-DP',\n",
    " 'within': 'OBS-DP',\n",
    " 'normal': 'OBS-DP',\n",
    " 'limits': 'OBS-DP',\n",
    " 'acute': 'OBS-DA',\n",
    " 'osseous': 'ANAT-DP',\n",
    " 'abnormalities': 'OBS-DA',\n",
    " 'cardiopulmonary': 'ANAT-DP',\n",
    " 'process': 'OBS-DA'\n",
    "}\n",
    "\n",
    "Example 2:\n",
    "Input text:\n",
    "\"FINAL REPORT HISTORY: Chest tube leak, to assess for pneumothorax. FINDINGS: In comparison with study of ___, the endotracheal tube and Swan-Ganz catheter have been removed. The left chest tube remains in place and there is no evidence of pneumothorax. Mild atelectatic changes are seen at the left base.\"\n",
    "\n",
    "Extracted entities:\n",
    "{\n",
    " 'endotracheal': 'OBS-DA',\n",
    " 'tube': 'OBS-DP',\n",
    " 'Swan - Ganz': 'OBS-DA',\n",
    " 'catheter': 'OBS-DA',\n",
    " 'left': 'ANAT-DP',\n",
    " 'chest': 'ANAT-DP',\n",
    " 'in place': 'OBS-DP',\n",
    " 'pneumothorax': 'OBS-DA',\n",
    " 'Mild': 'OBS-DP',\n",
    " 'atelectatic': 'OBS-DP',\n",
    " 'changes': 'OBS-DP',\n",
    " 'base': 'ANAT-DP'\n",
    "}\n",
    "\n",
    "Now, apply this classification to the provided text and return the result in JSON format as shown below:\n",
    "\n",
    "{\n",
    "    \"1\": {\"tokens\": \"Lungs\", \"label\": \"ANAT-DP\"},\n",
    "    \"2\": {\"tokens\": \"clear\", \"label\": \"OBS-DP\"},\n",
    "    ...\n",
    "}\n",
    "\n",
    "        \n",
    "        please only output the json, do not include any other information in the output.'''\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": text\n",
    "      }\n",
    "    ],\n",
    "    \"stream\": False\n",
    "  }\n",
    "\n",
    "  response = session.post(url, json=data)\n",
    "  entities = response.json()['message']['content']\n",
    "\n",
    "  return json.loads(entities)\n",
    "\n",
    "# Example usage\n",
    "with open('/home/hbchen/Projects/MedKGC/resource/radgraph/test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "json_result = None\n",
    "text = None\n",
    "\n",
    "for key, value in data.items():\n",
    "    json_result = value['labeler_1']['entities']\n",
    "    text = value['text']\n",
    "    break\n",
    "print(text)\n",
    "\n",
    "entities = extract_entities(text)\n",
    "\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_eval import compute_metrics\n",
    "from ner_eval import Entity\n",
    "import pprint   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINAL REPORT HISTORY : Chest tube leak , to assess for pneumothorax . FINDINGS : In comparison with study of ___ , the endotracheal tube and Swan - Ganz catheter have been removed . The left chest tube remains in place and there is no evidence of pneumothorax . Mild atelectatic changes are seen at the left base .'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import namedtuple\n",
    "\n",
    "Entity = namedtuple(\"Entity\", \"e_type start_offset end_offset\")\n",
    "\n",
    "\n",
    "def transform_radgraph_to_entity(json_result):\n",
    "    entities = []\n",
    "\n",
    "    for key, value in json_result.items():\n",
    "        e_type = value['label']\n",
    "        start_offset = value['start_ix']\n",
    "        end_offset = value['end_ix']\n",
    "        entities.append(Entity(e_type=e_type, start_offset=start_offset, end_offset=end_offset))\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "def transform_llm_response_to_entity(json_result, text):\n",
    "    entities = []\n",
    "    words = text.split()\n",
    "    word_index = 0\n",
    "    \n",
    "    for key, value in json_result.items():\n",
    "        token = value['tokens']\n",
    "        e_type = value['label']\n",
    "\n",
    "        # Find the start and end word offsets of the token in the text\n",
    "        while word_index < len(words):\n",
    "            if words[word_index] == token:\n",
    "                start_offset = word_index\n",
    "                end_offset = word_index\n",
    "                entities.append(Entity(e_type=e_type, start_offset=start_offset, end_offset=end_offset))\n",
    "                word_index += 1\n",
    "                break\n",
    "            word_index += 1\n",
    "    \n",
    "    return entities\n",
    "\n",
    "\n",
    "# Example usage\n",
    "with open('/home/hbchen/Projects/MedKGC/resource/radgraph/test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "json_result = None\n",
    "text = None\n",
    "\n",
    "index = 0\n",
    "for key, value in data.items():\n",
    "    json_result = value['labeler_1']['entities']\n",
    "    text = value['text']\n",
    "    \n",
    "    # break\n",
    "    index += 1\n",
    "    if index == 4:\n",
    "        break\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Entity(e_type='OBS-DA', start_offset=23, end_offset=23),\n",
       " Entity(e_type='OBS-DA', start_offset=24, end_offset=24),\n",
       " Entity(e_type='OBS-DA', start_offset=26, end_offset=28),\n",
       " Entity(e_type='OBS-DA', start_offset=29, end_offset=29),\n",
       " Entity(e_type='ANAT-DP', start_offset=35, end_offset=35),\n",
       " Entity(e_type='ANAT-DP', start_offset=36, end_offset=36),\n",
       " Entity(e_type='OBS-DP', start_offset=37, end_offset=37),\n",
       " Entity(e_type='OBS-DP', start_offset=39, end_offset=40),\n",
       " Entity(e_type='OBS-DA', start_offset=47, end_offset=47),\n",
       " Entity(e_type='OBS-DP', start_offset=49, end_offset=49),\n",
       " Entity(e_type='OBS-DP', start_offset=50, end_offset=50),\n",
       " Entity(e_type='OBS-DP', start_offset=51, end_offset=51),\n",
       " Entity(e_type='ANAT-DP', start_offset=56, end_offset=56),\n",
       " Entity(e_type='ANAT-DP', start_offset=57, end_offset=57)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = transform_radgraph_to_entity(json_result)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform_llm_response_to_entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 10:52:41 urllib3.connectionpool DEBUG: http://ollama.corinth.informatik.rwth-aachen.de:80 \"POST /api/chat HTTP/1.1\" 200 1240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'tokens': 'Chest', 'label': 'ANAT-DP'}, '2': {'tokens': 'tube', 'label': 'OBS-DA'}, '3': {'tokens': 'leak', 'label': 'OBS-DA'}, '4': {'tokens': 'pneumothorax', 'label': 'OBS-DA'}, '5': {'tokens': 'endotracheal', 'label': 'OBS-DA'}, '6': {'tokens': 'tube', 'label': 'OBS-DP'}, '7': {'tokens': 'Swan - Ganz', 'label': 'OBS-DA'}, '8': {'tokens': 'catheter', 'label': 'OBS-DA'}, '9': {'tokens': 'left', 'label': 'ANAT-DP'}, '10': {'tokens': 'chest', 'label': 'ANAT-DP'}, '11': {'tokens': 'in place', 'label': 'OBS-DP'}, '12': {'tokens': 'mild', 'label': 'OBS-DP'}, '13': {'tokens': 'atelectatic', 'label': 'OBS-DA'}, '14': {'tokens': 'changes', 'label': 'OBS-DA'}, '15': {'tokens': 'base', 'label': 'ANAT-DP'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Entity(e_type='ANAT-DP', start_offset=4, end_offset=4),\n",
       " Entity(e_type='OBS-DA', start_offset=5, end_offset=5),\n",
       " Entity(e_type='OBS-DA', start_offset=6, end_offset=6),\n",
       " Entity(e_type='OBS-DA', start_offset=11, end_offset=11),\n",
       " Entity(e_type='OBS-DA', start_offset=23, end_offset=23),\n",
       " Entity(e_type='OBS-DP', start_offset=24, end_offset=24)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(json_result\n",
    "print(\"transform_llm_response_to_entity\")\n",
    "json_result = extract_entities(text)\n",
    "print(json_result)\n",
    "\n",
    "pred = transform_llm_response_to_entity(json_result, text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 1,\n",
       " 'incorrect': 1,\n",
       " 'partial': 0,\n",
       " 'missed': 12,\n",
       " 'spurious': 4,\n",
       " 'precision': 0,\n",
       " 'recall': 0,\n",
       " 'actual': 6,\n",
       " 'possible': 14}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = ['OBS-DP', 'ANAT-DP', 'OBS-U', 'OBS-DA']\n",
    "result, evaluation_agg_entities_type = compute_metrics(y_true, pred, tag)\n",
    "\n",
    "result['strict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "之前的evaluation是用的token-level的F1，原因是bert的输出是token-level的。\n",
    "\n",
    "现在改成了word-level的F1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro F1\n",
    "定义：Macro F1 是对每个类别单独计算 F1 分数后，再进行算术平均。它给予每个类别相同的重要性，因此在类别不平衡时表现更佳。\n",
    "\n",
    "我们并不知道任何分类的信息，无法计算 Macro F1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Micro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "def compare(result_entity, target):\n",
    "    tokens = result_entity[\"tokens\"]\n",
    "    label = result_entity[\"label\"]\n",
    "\n",
    "    target_tokens = target[\"tokens\"]\n",
    "    target_label = target[\"label\"]\n",
    "\n",
    "    # For entity recognition, a predicted entity is considered correct if the predicted span boundaries and predicted entity type are both correct\n",
    "    if tokens == target_tokens and label == target_label:\n",
    "        return True\n",
    "\n",
    "    return result_entity == target\n",
    "\n",
    "import nereval\n",
    "from nereval import Entity\n",
    "\n",
    "def prepare_target_from_radgraph(data):\n",
    "    entities_list = []\n",
    "    \n",
    "    for file_key, file_value in data.items():\n",
    "        if 'labeler_1' in file_value:\n",
    "            labeler_1 = file_value['labeler_1']\n",
    "            if 'entities' in labeler_1:\n",
    "                entities = labeler_1['entities']\n",
    "                for entity_id, entity_info in entities.items():\n",
    "                    entity = Entity(\n",
    "                        entity_info['tokens'],\n",
    "                        entity_info['label'],\n",
    "                        entity_info['start_ix']\n",
    "                    )\n",
    "                    entities_list.append(entity)\n",
    "        elif 'entities' in file_value:\n",
    "            entities = file_value['entities']\n",
    "            for entity_id, entity_info in entities.items():\n",
    "                entity = Entity(\n",
    "                    entity_info['tokens'],\n",
    "                    entity_info['label'],\n",
    "                    entity_info['start_ix']\n",
    "                )\n",
    "                entities_list.append(entity)\n",
    "    \n",
    "    return entities_list\n",
    "\n",
    "# Example usage\n",
    "with open('/home/hbchen/Projects/MedKGC/resource/radgraph/test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "y_true = prepare_target_from_radgraph(data)\n",
    "pprint.pprint(entities)\n",
    "\n",
    "\n",
    "def prepare_result_from_text(result, text):\n",
    "    entities_list = []\n",
    "    \n",
    "    for entity_id, entity_info in result.items():\n",
    "        entity = Entity(\n",
    "            entity_info['tokens'],\n",
    "            entity_info['label'],\n",
    "            entity_info.get('start_ix', 0)  # Assuming start_ix is the key for the starting index\n",
    "        )\n",
    "        entities_list.append(entity)\n",
    "    \n",
    "    return entities_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = prepare_target_from_radgrapgh(data)\n",
    "pred = prepare_result_from_text(pred)\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=['LOC', 'PER'])\n",
    "\n",
    "# Returns overall metrics and metrics for each tag\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ner_evaluation library\n",
    "from ner_evaluation import compute_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actual': 4,\n",
      " 'correct': 3,\n",
      " 'incorrect': 1,\n",
      " 'missed': 0,\n",
      " 'partial': 0,\n",
      " 'possible': 4,\n",
      " 'precision': 0,\n",
      " 'recall': 0,\n",
      " 'spurious': 0}\n"
     ]
    }
   ],
   "source": [
    "from ner_eval import compute_metrics\n",
    "from ner_eval import Entity\n",
    "import pprint   \n",
    "\n",
    "true = [Entity(e_type='MISC', start_offset=12, end_offset=12),\n",
    "        Entity(e_type='LOC', start_offset=15, end_offset=15),\n",
    "        Entity(e_type='PER', start_offset=37, end_offset=39),\n",
    "        Entity(e_type='ORG', start_offset=45, end_offset=46)]\n",
    "\n",
    "pred = [Entity(e_type='MISC', start_offset=12, end_offset=12),\n",
    "        Entity(e_type='LOC', start_offset=15, end_offset=15),\n",
    "        Entity(e_type='PER', start_offset=37, end_offset=39),\n",
    "        Entity(e_type='LOC', start_offset=45, end_offset=46)]\n",
    "\n",
    "tags = ['LOC', 'PER', 'ORG', 'MISC']\n",
    "\n",
    "\n",
    "results, evaluation_agg_entities_type = compute_metrics(true, pred, tags)\n",
    "\n",
    "pprint.pprint(results[\"strict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nervaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 10:41:51 root DEBUG: Imported 2 predictions for 2 true examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_type': {'actual': 3,\n",
      "              'correct': 3,\n",
      "              'f1': 1.0,\n",
      "              'incorrect': 0,\n",
      "              'missed': 0,\n",
      "              'partial': 0,\n",
      "              'possible': 3,\n",
      "              'precision': 1.0,\n",
      "              'recall': 1.0,\n",
      "              'spurious': 0},\n",
      " 'exact': {'actual': 3,\n",
      "           'correct': 2,\n",
      "           'f1': 0.6666666666666666,\n",
      "           'incorrect': 1,\n",
      "           'missed': 0,\n",
      "           'partial': 0,\n",
      "           'possible': 3,\n",
      "           'precision': 0.6666666666666666,\n",
      "           'recall': 0.6666666666666666,\n",
      "           'spurious': 0},\n",
      " 'partial': {'actual': 3,\n",
      "             'correct': 2,\n",
      "             'f1': 0.8333333333333334,\n",
      "             'incorrect': 0,\n",
      "             'missed': 0,\n",
      "             'partial': 1,\n",
      "             'possible': 3,\n",
      "             'precision': 0.8333333333333334,\n",
      "             'recall': 0.8333333333333334,\n",
      "             'spurious': 0},\n",
      " 'strict': {'actual': 3,\n",
      "            'correct': 2,\n",
      "            'f1': 0.6666666666666666,\n",
      "            'incorrect': 1,\n",
      "            'missed': 0,\n",
      "            'partial': 0,\n",
      "            'possible': 3,\n",
      "            'precision': 0.6666666666666666,\n",
      "            'recall': 0.6666666666666666,\n",
      "            'spurious': 0}}\n"
     ]
    }
   ],
   "source": [
    "true = [\n",
    "    [{\"label\": \"PER\", \"start\": 2, \"end\": 4}],\n",
    "    [{\"label\": \"LOC\", \"start\": 1, \"end\": 2},\n",
    "     {\"label\": \"LOC\", \"start\": 3, \"end\": 4}]\n",
    "]\n",
    "\n",
    "pred = [\n",
    "    [{\"label\": \"PER\", \"start\": 2, \"end\": 4}],\n",
    "    [{\"label\": \"LOC\", \"start\": 1, \"end\": 1},\n",
    "     {\"label\": \"LOC\", \"start\": 3, \"end\": 4}]\n",
    "]\n",
    "\n",
    "from nervaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(true, pred, tags=['LOC', 'PER'])\n",
    "\n",
    "# Returns overall metrics and metrics for each tag\n",
    "\n",
    "results, results_per_tag, result_indices, result_indices_by_tag = evaluator.evaluate()\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER with RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot = {\n",
    "            \"1\": {\n",
    "                \"tokens\": \"Lungs\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": []\n",
    "            },\n",
    "            \"2\": {\n",
    "                \"tokens\": \"clear\",\n",
    "                \"label\": \"OBS-DP\",\n",
    "                \"relations\": [\n",
    "                    [\n",
    "                        \"located_at\",\n",
    "                        \"1\"\n",
    "                    ]\n",
    "                ]\n",
    "            },\n",
    "            \"3\": {\n",
    "                \"tokens\": \"Normal\",\n",
    "                \"label\": \"OBS-DP\",\n",
    "                \"relations\": [\n",
    "                    [\n",
    "                        \"located_at\",\n",
    "                        \"4\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"located_at\",\n",
    "                        \"5\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"located_at\",\n",
    "                        \"7\"\n",
    "                    ]\n",
    "                ]\n",
    "            },\n",
    "            \"4\": {\n",
    "                \"tokens\": \"cardiomediastinal\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": []\n",
    "            },\n",
    "            \"5\": {\n",
    "                \"tokens\": \"hilar\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": []\n",
    "            },\n",
    "            \"6\": {\n",
    "                \"tokens\": \"silhouettes\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": [\n",
    "                    [\n",
    "                        \"modify\",\n",
    "                        \"4\"\n",
    "                    ],\n",
    "                    [\n",
    "                        \"modify\",\n",
    "                        \"5\"\n",
    "                    ]\n",
    "                ]\n",
    "            },\n",
    "            \"7\": {\n",
    "                \"tokens\": \"pleural\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": []\n",
    "            },\n",
    "            \"8\": {\n",
    "                \"tokens\": \"surfaces\",\n",
    "                \"label\": \"ANAT-DP\",\n",
    "                \"relations\": [\n",
    "                    [\n",
    "                        \"modify\",\n",
    "                        \"7\"\n",
    "                    ]\n",
    "                ]\n",
    "            }\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkgc",
   "language": "python",
   "name": "medkgc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
