{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5981ab",
   "metadata": {},
   "source": [
    "# medical NER\n",
    "## BlueBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "# 加载模型和分词器\n",
    "model_name = \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# 准备文本\n",
    "text = \"Patient with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is showing signs of improvement.\"\n",
    "\n",
    "# 编码文本\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 预测实体\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "\n",
    "# 解码预测结果\n",
    "logits = outputs.logits\n",
    "predicted_token_classes = logits.argmax(-1).squeeze().tolist()\n",
    "\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze().tolist())\n",
    "predictions = [model.config.id2label[token_class] for token_class in predicted_token_classes]\n",
    "\n",
    "\n",
    "# 打印每个词及其预测实体类别\n",
    "for token, prediction in zip(tokens, predictions):\n",
    "    print(f\"{token}: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7571323",
   "metadata": {},
   "source": [
    "## PubMedBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# 加载模型和分词器\n",
    "\n",
    "model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# 准备文本\n",
    "text = \"Recent studies on SARS-CoV-2 suggest potential vaccine targets.\"\n",
    "text = \"Patient with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is showing signs of improvement.\"\n",
    "text = 'CASE: A 28-year-old previously healthy man presented with a 6-week history of palpitations. The symptoms occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea. Except for a grade 2/6 holosystolic tricuspid regurgitation murmur (best heard at the left sternal border with inspiratory accentuation), physical examination yielded unremarkable findings.'\n",
    "\n",
    "\n",
    "# 编码文本\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 预测实体\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "# print('\\n\\n', logits)\n",
    "\n",
    "# 解码预测结果\n",
    "predicted_token_classes = logits.argmax(-1)\n",
    "print('\\n\\n', predicted_token_classes)\n",
    "\n",
    "tokens = inputs.tokens()\n",
    "predictions = [model.config.id2label[predicted_token_classes[0][i].item()] for i in range(len(tokens))]\n",
    "\n",
    "# 输出结果\n",
    "for token, prediction in zip(tokens, predictions):\n",
    "    print(f\"{token}: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f2ce0",
   "metadata": {},
   "source": [
    "## RoBERTa-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ebe052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"abymmathew/RoBERTa-large-PM-M3-Voc-hf-finetuned-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"abymmathew/RoBERTa-large-PM-M3-Voc-hf-finetuned-ner\")\n",
    "\n",
    "text = 'CASE: A 28-year-old previously healthy man presented with a 6-week history of palpitations. The symptoms occurred during rest, 2–3 times per week, lasted up to 30 minutes at a time and were associated with dyspnea. Except for a grade 2/6 holosystolic tricuspid regurgitation murmur (best heard at the left sternal border with inspiratory accentuation), physical examination yielded unremarkable findings.'\n",
    "text = \"Recent studies on SARS-CoV-2 suggest potential vaccine targets.\"\n",
    "text = \"Patient with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is showing signs of improvement.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 编码文本\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# 预测实体\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    print(logits.shape)\n",
    "\n",
    "\n",
    "# 解码预测结果\n",
    "predicted_token_classes = logits.argmax(-1)\n",
    "tokens = inputs.tokens()\n",
    "predictions = [model.config.id2label[predicted_token_classes[0][i].item()] for i in range(len(tokens))]\n",
    "for token, prediction in zip(tokens, predictions):\n",
    "    print(f\"{token}: {prediction}\")\n",
    "\n",
    "\n",
    "# print label\n",
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faaec73",
   "metadata": {},
   "source": [
    "# RadGraph MIMIC-CXR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1822f0d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'end_ix': 36,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [],\n",
      "       'start_ix': 36,\n",
      "       'tokens': 'Lungs'},\n",
      " '2': {'end_ix': 38,\n",
      "       'label': 'OBS-DP',\n",
      "       'relations': [['located_at', '1']],\n",
      "       'start_ix': 38,\n",
      "       'tokens': 'clear'},\n",
      " '3': {'end_ix': 40,\n",
      "       'label': 'OBS-DP',\n",
      "       'relations': [['located_at', '4'],\n",
      "                     ['located_at', '5'],\n",
      "                     ['located_at', '7']],\n",
      "       'start_ix': 40,\n",
      "       'tokens': 'Normal'},\n",
      " '4': {'end_ix': 41,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [],\n",
      "       'start_ix': 41,\n",
      "       'tokens': 'cardiomediastinal'},\n",
      " '5': {'end_ix': 43,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [],\n",
      "       'start_ix': 43,\n",
      "       'tokens': 'hilar'},\n",
      " '6': {'end_ix': 44,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [['modify', '4'], ['modify', '5']],\n",
      "       'start_ix': 44,\n",
      "       'tokens': 'silhouettes'},\n",
      " '7': {'end_ix': 46,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [],\n",
      "       'start_ix': 46,\n",
      "       'tokens': 'pleural'},\n",
      " '8': {'end_ix': 47,\n",
      "       'label': 'ANAT-DP',\n",
      "       'relations': [['modify', '7']],\n",
      "       'start_ix': 47,\n",
      "       'tokens': 'surfaces'}}\n"
     ]
    }
   ],
   "source": [
    "graph_train_path = '/DATA1/llm-research/RadGraph/physionet.org/files/radgraph/1.0.0/train.json'\n",
    "\n",
    "import json\n",
    "with open(graph_train_path, 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "import pprint\n",
    "# pprint.pprint(train_data)\n",
    "\n",
    "pprint.pprint(train_data['p18/p18004941/s58821758.txt']['entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450f756",
   "metadata": {},
   "source": [
    "Dataset of MIMIC\n",
    ">       '15': {'end_ix': 69,\n",
    "              'label': 'ANAT-DP',\n",
    "              'relations': [],\n",
    "              'start_ix': 69,\n",
    "              'tokens': 'heart'},\n",
    "       '16': {'end_ix': 70,\n",
    "              'label': 'ANAT-DP',\n",
    "              'relations': [['modify',\n",
    "                            '15']],\n",
    "              'start_ix': 70,\n",
    "              'tokens': 'border'},\n",
    "\n",
    "Training dataset dose not have consider the entity with discontinuous tokens, so the model can not predict the entity with discontinuous tokens.\n",
    "> German football team won the world and European championships in 1974 and 1972 respectively.\n",
    "\n",
    "Should be:  \n",
    "'World championship' and 'European championship'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f953aff",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_data['p18/p18004941/s58821758.txt'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9083a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_data['p18/p18004941/s58821758.txt']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbae65",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "train_data['p18/p18004941/s58821758.txt']['text'].split(' ')[47]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce94495",
   "metadata": {},
   "source": [
    "predict_examples = [[g, label, word, e], [g, label, word, e], ...]\n",
    "\n",
    "test_dataset = NerDataset(predict_examples\n",
    "\n",
    "sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    sampler=sampler,\n",
    "    batch_size=32, # you can adjust evaluation batch size, we prefer using 32\n",
    "    collate_fn=default_data_collator,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b165e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'abstract_id': 14145090,\n",
    " 'text': 'velvet antlers vas are commonly used in traditional chinese medicine and invigorant and contain many PET components for health promotion the velvet antler peptide svap is one of active components in vas based on structural study the svap interacts with tgfÎ² receptors and disrupts the tgfÎ² pathway we hypothesized that svap prevents cardiac fibrosis from pressure overload by blocking tgfÎ² signaling SDRs underwent TAC tac or a sham operation T3 one month rats received either svap mgkgday or vehicle for an additional one month tac surgery induced significant cardiac dysfunction FB activation and fibrosis these effects were improved by treatment with svap in the heart tissue tac remarkably increased the expression of tgfÎ² and connective tissue growth factor ctgf ROS species C2 and the phosphorylation C2 of smad and ERK kinases erk svap inhibited the increases in reactive oxygen species C2 ctgf expression and the phosphorylation of smad and erk but not tgfÎ² expression in cultured cardiac fibroblasts angiotensin ii ang ii had similar effects compared to tac surgery such as increases in Î±smapositive CFs and collagen synthesis svap eliminated these effects by disrupting tgfÎ² IB to its receptors and blocking ang iitgfÎ² downstream signaling these results demonstrated that svap has antifibrotic effects by blocking the tgfÎ² pathway in CFs',\n",
    " 'location': [63],\n",
    " 'label': ['transverse aortic constriction']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a['text'].split(' ')[63]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c4dfb",
   "metadata": {},
   "source": [
    "# Pure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00833a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = '{\"clusters\": [[[6, 17], [32, 32]], [[4, 4], [55, 55], [91, 91]], [[58, 62], [64, 64], [79, 79]]], \"sentences\": [[\"This\", \"paper\", \"presents\", \"an\", \"algorithm\", \"for\", \"computing\", \"optical\", \"flow\", \",\", \"shape\", \",\", \"motion\", \",\", \"lighting\", \",\", \"and\", \"albedo\", \"from\", \"an\", \"image\", \"sequence\", \"of\", \"a\", \"rigidly-moving\", \"Lambertian\", \"object\", \"under\", \"distant\", \"illumination\", \".\"], [\"The\", \"problem\", \"is\", \"formulated\", \"in\", \"a\", \"manner\", \"that\", \"subsumes\", \"structure\", \"from\", \"motion\", \",\", \"multi-view\", \"stereo\", \",\", \"and\", \"photo-metric\", \"stereo\", \"as\", \"special\", \"cases\", \".\"], [\"The\", \"algorithm\", \"utilizes\", \"both\", \"spatial\", \"and\", \"temporal\", \"intensity\", \"variation\", \"as\", \"cues\", \":\", \"the\", \"former\", \"constrains\", \"flow\", \"and\", \"the\", \"latter\", \"constrains\", \"surface\", \"orientation\", \";\", \"combining\", \"both\", \"cues\", \"enables\", \"dense\", \"reconstruction\", \"of\", \"both\", \"textured\", \"and\", \"texture-less\", \"surfaces\", \".\"], [\"The\", \"algorithm\", \"works\", \"by\", \"iteratively\", \"estimating\", \"affine\", \"camera\", \"parameters\", \",\", \"illumination\", \",\", \"shape\", \",\", \"and\", \"albedo\", \"in\", \"an\", \"alternating\", \"fashion\", \".\"], [\"Results\", \"are\", \"demonstrated\", \"on\", \"videos\", \"of\", \"hand-held\", \"objects\", \"moving\", \"in\", \"front\", \"of\", \"a\", \"fixed\", \"light\", \"and\", \"camera\", \".\"]], \"ner\": [[[4, 4, \"Generic\"], [6, 17, \"Task\"], [20, 21, \"Material\"], [24, 26, \"Material\"], [28, 29, \"OtherScientificTerm\"]], [[32, 32, \"Generic\"], [42, 42, \"Material\"], [44, 45, \"Material\"], [48, 49, \"Material\"]], [[55, 55, \"Generic\"], [58, 62, \"OtherScientificTerm\"], [64, 64, \"Generic\"], [67, 67, \"Generic\"], [69, 69, \"OtherScientificTerm\"], [72, 72, \"Generic\"], [74, 75, \"OtherScientificTerm\"], [79, 79, \"Generic\"], [81, 88, \"Task\"]], [[91, 91, \"Generic\"], [95, 105, \"Method\"]], [[115, 118, \"Material\"]]], \"relations\": [[[4, 4, 6, 17, \"USED-FOR\"], [20, 21, 4, 4, \"USED-FOR\"], [24, 26, 20, 21, \"FEATURE-OF\"], [28, 29, 24, 26, \"FEATURE-OF\"]], [[42, 42, 44, 45, \"CONJUNCTION\"], [44, 45, 48, 49, \"CONJUNCTION\"]], [[58, 62, 55, 55, \"USED-FOR\"], [67, 67, 64, 64, \"HYPONYM-OF\"], [67, 67, 69, 69, \"USED-FOR\"], [67, 67, 72, 72, \"CONJUNCTION\"], [72, 72, 64, 64, \"HYPONYM-OF\"], [72, 72, 74, 75, \"USED-FOR\"], [79, 79, 81, 88, \"USED-FOR\"]], [[95, 105, 91, 91, \"USED-FOR\"]], []], \"doc_key\": \"ICCV_2003_158_abs\"}'\n",
    "\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "pprint.pprint(json.loads(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74cf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model allenai/scibert_scivocab_uncased\n",
    "# Load model directly\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(\"allenai/scibert_scivocab_uncased\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fecf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "# make a sentence \n",
    "sentence = Sentence(\"Behavioral abnormalities in the Fmr1 KO2 Mouse Model of Fragile X Syndrome\")\n",
    "\n",
    "# load biomedical NER tagger\n",
    "tagger = Classifier.load(\"hunflair\")\n",
    "\n",
    "# tag sentence\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eff6c4",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966b92cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50b1472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n",
      "10.2\n",
      "7605\n",
      "True\n",
      "NVIDIA H100 PCIe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c804e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkgc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
