{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read enetiy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of entities: 1250\n",
      "\n",
      "First 2 entities:\n",
      "1.\n",
      "{ 'Lungs': { 'label': 'ANAT-DP',\n",
      "             'normalization': None,\n",
      "             'reports': [ {'p18/p18004941/s58821758.txt': {'end_ix': 36, 'start_ix': 36}},\n",
      "                          {'p18/p18003081/s53302126.txt': {'end_ix': 52, 'start_ix': 52}},\n",
      "                          {'p18/p18001922/s52638004.txt': {'end_ix': 46, 'start_ix': 46}},\n",
      "                          {'p18/p18001922/s52288833.txt': {'end_ix': 52, 'start_ix': 52}},\n",
      "                          {'p15/p15165563/s51659523.txt': {'end_ix': 110, 'start_ix': 110}},\n",
      "                          {'p15/p15004061/s56845046.txt': {'end_ix': 42, 'start_ix': 42}},\n",
      "                          {'p15/p15078112/s51228277.txt': {'end_ix': 75, 'start_ix': 75}},\n",
      "                          {'p15/p15078112/s58703686.txt': {'end_ix': 66, 'start_ix': 66}},\n",
      "                          {'p18/p18026902/s53920289.txt': {'end_ix': 63, 'start_ix': 63}},\n",
      "                          {'p18/p18026902/s51741672.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p15/p15002538/s51219765.txt': {'end_ix': 46, 'start_ix': 46}},\n",
      "                          {'p18/p18019295/s57254021.txt': {'end_ix': 66, 'start_ix': 66}},\n",
      "                          {'p18/p18019295/s52492192.txt': {'end_ix': 44, 'start_ix': 44}},\n",
      "                          {'p10/p10002930/s55885481.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p15/p15003988/s51924979.txt': {'end_ix': 69, 'start_ix': 69}},\n",
      "                          {'p15/p15002074/s52562523.txt': {'end_ix': 113, 'start_ix': 113}},\n",
      "                          {'p10/p10003637/s51461467.txt': {'end_ix': 74, 'start_ix': 74}},\n",
      "                          {'p15/p15000393/s59128455.txt': {'end_ix': 56, 'start_ix': 56}},\n",
      "                          {'p10/p10002428/s58581921.txt': {'end_ix': 33, 'start_ix': 33}},\n",
      "                          {'p15/p15003026/s53882677.txt': {'end_ix': 32, 'start_ix': 32}},\n",
      "                          {'p18/p18011616/s50630819.txt': {'end_ix': 54, 'start_ix': 54}},\n",
      "                          {'p18/p18028180/s53423151.txt': {'end_ix': 44, 'start_ix': 44}},\n",
      "                          {'p18/p18028180/s57601456.txt': {'end_ix': 35, 'start_ix': 35}},\n",
      "                          {'p18/p18000379/s59391463.txt': {'end_ix': 71, 'start_ix': 71}},\n",
      "                          {'p18/p18000379/s58920421.txt': {'end_ix': 81, 'start_ix': 81}}]}}\n",
      "2.\n",
      "{ 'clear': { 'label': 'OBS-DP',\n",
      "             'normalization': None,\n",
      "             'reports': [ {'p18/p18004941/s58821758.txt': {'end_ix': 38, 'start_ix': 38}},\n",
      "                          {'p18/p18004941/s58034164.txt': {'end_ix': 102, 'start_ix': 102}},\n",
      "                          {'p18/p18003081/s52532534.txt': {'end_ix': 59, 'start_ix': 59}},\n",
      "                          {'p18/p18003081/s50577366.txt': {'end_ix': 63, 'start_ix': 63}},\n",
      "                          {'p18/p18003081/s53302126.txt': {'end_ix': 59, 'start_ix': 59}},\n",
      "                          {'p18/p18023211/s50231046.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p18/p18023211/s56555187.txt': {'end_ix': 90, 'start_ix': 90}},\n",
      "                          {'p18/p18001922/s52326539.txt': {'end_ix': 22, 'start_ix': 22}},\n",
      "                          {'p15/p15165563/s56337929.txt': {'end_ix': 115, 'start_ix': 115}},\n",
      "                          {'p15/p15165563/s57194811.txt': {'end_ix': 31, 'start_ix': 31}},\n",
      "                          {'p15/p15004061/s56845046.txt': {'end_ix': 47, 'start_ix': 47}},\n",
      "                          {'p15/p15001073/s52168754.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p15/p15078112/s51228277.txt': {'end_ix': 78, 'start_ix': 78}},\n",
      "                          {'p15/p15078112/s59479753.txt': {'end_ix': 44, 'start_ix': 44}},\n",
      "                          {'p15/p15078112/s59479753.txt': {'end_ix': 85, 'start_ix': 85}},\n",
      "                          {'p15/p15078112/s58703686.txt': {'end_ix': 68, 'start_ix': 68}},\n",
      "                          {'p18/p18026902/s53920289.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p18/p18026902/s51741672.txt': {'end_ix': 70, 'start_ix': 70}},\n",
      "                          {'p15/p15003294/s51224077.txt': {'end_ix': 36, 'start_ix': 36}},\n",
      "                          {'p15/p15003294/s51225513.txt': {'end_ix': 66, 'start_ix': 66}},\n",
      "                          {'p15/p15003294/s58755630.txt': {'end_ix': 24, 'start_ix': 24}},\n",
      "                          {'p15/p15003294/s54302152.txt': {'end_ix': 56, 'start_ix': 56}},\n",
      "                          {'p15/p15003294/s57007434.txt': {'end_ix': 29, 'start_ix': 29}},\n",
      "                          {'p18/p18012427/s54748444.txt': {'end_ix': 53, 'start_ix': 53}},\n",
      "                          {'p18/p18012427/s55382203.txt': {'end_ix': 71, 'start_ix': 71}},\n",
      "                          {'p18/p18012427/s54022564.txt': {'end_ix': 50, 'start_ix': 50}},\n",
      "                          {'p18/p18010079/s52730761.txt': {'end_ix': 45, 'start_ix': 45}},\n",
      "                          {'p15/p15002538/s58326480.txt': {'end_ix': 40, 'start_ix': 40}},\n",
      "                          {'p15/p15002538/s51219765.txt': {'end_ix': 48, 'start_ix': 48}},\n",
      "                          {'p18/p18019295/s57254021.txt': {'end_ix': 68, 'start_ix': 68}},\n",
      "                          {'p18/p18019295/s52794569.txt': {'end_ix': 38, 'start_ix': 38}},\n",
      "                          {'p18/p18002106/s56517301.txt': {'end_ix': 100, 'start_ix': 100}},\n",
      "                          {'p18/p18003894/s58464660.txt': {'end_ix': 60, 'start_ix': 60}},\n",
      "                          {'p18/p18003894/s56902065.txt': {'end_ix': 83, 'start_ix': 83}},\n",
      "                          {'p10/p10003502/s57812613.txt': {'end_ix': 57, 'start_ix': 57}},\n",
      "                          {'p15/p15006483/s57974872.txt': {'end_ix': 31, 'start_ix': 31}},\n",
      "                          {'p15/p15006483/s57012181.txt': {'end_ix': 80, 'start_ix': 80}},\n",
      "                          {'p10/p10002930/s55885481.txt': {'end_ix': 67, 'start_ix': 67}},\n",
      "                          {'p10/p10007795/s57491780.txt': {'end_ix': 90, 'start_ix': 90}},\n",
      "                          {'p10/p10007795/s56375093.txt': {'end_ix': 87, 'start_ix': 87}},\n",
      "                          {'p10/p10005866/s56175428.txt': {'end_ix': 135, 'start_ix': 135}},\n",
      "                          {'p15/p15002957/s50480029.txt': {'end_ix': 32, 'start_ix': 32}},\n",
      "                          {'p10/p10002661/s53368584.txt': {'end_ix': 36, 'start_ix': 36}},\n",
      "                          {'p15/p15003988/s51924979.txt': {'end_ix': 74, 'start_ix': 74}},\n",
      "                          {'p10/p10003052/s58630288.txt': {'end_ix': 48, 'start_ix': 48}},\n",
      "                          {'p18/p18017363/s53531162.txt': {'end_ix': 35, 'start_ix': 35}},\n",
      "                          {'p15/p15002074/s52562523.txt': {'end_ix': 116, 'start_ix': 116}},\n",
      "                          {'p10/p10005368/s54510564.txt': {'end_ix': 38, 'start_ix': 38}},\n",
      "                          {'p15/p15003122/s55694380.txt': {'end_ix': 61, 'start_ix': 61}},\n",
      "                          {'p18/p18015004/s57985812.txt': {'end_ix': 31, 'start_ix': 31}},\n",
      "                          {'p18/p18015004/s58110495.txt': {'end_ix': 46, 'start_ix': 46}},\n",
      "                          {'p18/p18015004/s56533254.txt': {'end_ix': 94, 'start_ix': 94}},\n",
      "                          {'p10/p10003637/s51461467.txt': {'end_ix': 76, 'start_ix': 76}},\n",
      "                          {'p18/p18002668/s52520031.txt': {'end_ix': 30, 'start_ix': 30}},\n",
      "                          {'p10/p10003019/s56635465.txt': {'end_ix': 79, 'start_ix': 79}},\n",
      "                          {'p10/p10003019/s56635465.txt': {'end_ix': 112, 'start_ix': 112}},\n",
      "                          {'p10/p10003019/s59005604.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p10/p10003019/s55931751.txt': {'end_ix': 126, 'start_ix': 126}},\n",
      "                          {'p10/p10003019/s59607556.txt': {'end_ix': 121, 'start_ix': 121}},\n",
      "                          {'p18/p18001529/s58906888.txt': {'end_ix': 30, 'start_ix': 30}},\n",
      "                          {'p18/p18001649/s53184881.txt': {'end_ix': 45, 'start_ix': 45}},\n",
      "                          {'p18/p18001523/s58950691.txt': {'end_ix': 19, 'start_ix': 19}},\n",
      "                          {'p18/p18001523/s53676202.txt': {'end_ix': 53, 'start_ix': 53}},\n",
      "                          {'p15/p15003289/s54505463.txt': {'end_ix': 40, 'start_ix': 40}},\n",
      "                          {'p15/p15000393/s53701643.txt': {'end_ix': 87, 'start_ix': 87}},\n",
      "                          {'p15/p15000393/s51634677.txt': {'end_ix': 66, 'start_ix': 66}},\n",
      "                          {'p15/p15000393/s59128455.txt': {'end_ix': 59, 'start_ix': 59}},\n",
      "                          {'p10/p10002428/s57321224.txt': {'end_ix': 57, 'start_ix': 57}},\n",
      "                          {'p10/p10002428/s59258773.txt': {'end_ix': 49, 'start_ix': 49}},\n",
      "                          {'p10/p10002428/s56836542.txt': {'end_ix': 81, 'start_ix': 81}},\n",
      "                          {'p10/p10002428/s58581921.txt': {'end_ix': 97, 'start_ix': 97}},\n",
      "                          {'p10/p10002428/s57064083.txt': {'end_ix': 133, 'start_ix': 133}},\n",
      "                          {'p18/p18006842/s59597753.txt': {'end_ix': 84, 'start_ix': 84}},\n",
      "                          {'p15/p15002496/s51438936.txt': {'end_ix': 113, 'start_ix': 113}},\n",
      "                          {'p15/p15002496/s53899716.txt': {'end_ix': 37, 'start_ix': 37}},\n",
      "                          {'p15/p15002496/s55634030.txt': {'end_ix': 56, 'start_ix': 56}},\n",
      "                          {'p15/p15002496/s53190310.txt': {'end_ix': 74, 'start_ix': 74}},\n",
      "                          {'p15/p15002496/s57105647.txt': {'end_ix': 66, 'start_ix': 66}},\n",
      "                          {'p15/p15002496/s55374744.txt': {'end_ix': 48, 'start_ix': 48}},\n",
      "                          {'p18/p18001786/s56916492.txt': {'end_ix': 43, 'start_ix': 43}},\n",
      "                          {'p15/p15003026/s53882677.txt': {'end_ix': 34, 'start_ix': 34}},\n",
      "                          {'p15/p15002397/s57752049.txt': {'end_ix': 26, 'start_ix': 26}},\n",
      "                          {'p18/p18011616/s57021204.txt': {'end_ix': 74, 'start_ix': 74}},\n",
      "                          {'p18/p18011616/s50630819.txt': {'end_ix': 59, 'start_ix': 59}},\n",
      "                          {'p18/p18028180/s54705304.txt': {'end_ix': 37, 'start_ix': 37}},\n",
      "                          {'p18/p18028180/s50287111.txt': {'end_ix': 60, 'start_ix': 60}},\n",
      "                          {'p18/p18028180/s57601456.txt': {'end_ix': 41, 'start_ix': 41}},\n",
      "                          {'p18/p18000379/s59391463.txt': {'end_ix': 73, 'start_ix': 73}},\n",
      "                          {'p18/p18000379/s55947854.txt': {'end_ix': 63, 'start_ix': 63}},\n",
      "                          {'p18/p18000379/s58920421.txt': {'end_ix': 82, 'start_ix': 82}},\n",
      "                          {'p18/p18000379/s57979934.txt': {'end_ix': 73, 'start_ix': 73}},\n",
      "                          {'p15/p15002643/s51061808.txt': {'end_ix': 60, 'start_ix': 60}},\n",
      "                          {'p18/p18017572/s52030715.txt': {'end_ix': 38, 'start_ix': 38}},\n",
      "                          {'p18/p18017572/s54836720.txt': {'end_ix': 73, 'start_ix': 73}},\n",
      "                          {'p15/p15001834/s54486241.txt': {'end_ix': 64, 'start_ix': 64}},\n",
      "                          {'p15/p15001834/s54265476.txt': {'end_ix': 28, 'start_ix': 28}},\n",
      "                          {'p15/p15001834/s52944718.txt': {'end_ix': 24, 'start_ix': 24}},\n",
      "                          {'p15/p15001834/s50931830.txt': {'end_ix': 26, 'start_ix': 26}}]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "file_path = '../resource/all_unique_entities.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    all_entities = json.load(f)\n",
    "\n",
    "# Print total number of entities\n",
    "print(f\"Total number of entities: {len(all_entities)}\")\n",
    "\n",
    "# Print first 2 entities\n",
    "print(\"\\nFirst 2 entities:\")\n",
    "for i, (key, value) in enumerate(list(all_entities.items())[:2], 1):\n",
    "    print(f\"{i}.\")\n",
    "    pprint({key: value}, width=100, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppoed result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "            \"normalization\":{\n",
    "                                \"UMLS\" : {\n",
    "                                    \"ui\": \"C0000005\",\n",
    "                                    \"name\": \"Blood\",\n",
    "                                    \"definition\": {\n",
    "                                        \"definition\": \"The fluid that circulates in the vascular system of a living organism.\",\n",
    "                                        \"source\": \"MSH\"\n",
    "                                        }\n",
    "                                    }\n",
    "                            }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the entity file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lungs C0024109 https://uts-ws.nlm.nih.gov/rest/content/2024AA/CUI/C0024109\n",
      "('Body Part, Organ, or Organ Component',\n",
      " 'Lobular organ the parenchyma of which consists of air-filled alveoli which '\n",
      " 'communicate with the tracheobronchial tree. Examples: There are only two '\n",
      " 'instances, right lung and left lung.',\n",
      " 'UWDA')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "# 设置API密钥和基础URL\n",
    "API_KEY = \"751b12fd-192a-4a6d-985d-9b094c99d3c8\"\n",
    "BASE_URL = \"https://uts-ws.nlm.nih.gov/rest\"\n",
    "\n",
    "\n",
    "# return json\n",
    "def search_umls_api(term, version=\"current\"):\n",
    "    url = f\"{BASE_URL}/search/{version}\"\n",
    "    params = {\n",
    "        \"string\": term,\n",
    "        \"apiKey\": API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"查询失败: {term}, 状态码: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "# TODO for further development\n",
    "def best_match(entity, results_list):\n",
    "    # for now just return the first result\n",
    "    result = results_list[0]\n",
    "\n",
    "    # calculate the levenshtein distance between entity and result['name']\n",
    "    # if distance is less than a threshold, return result['ui'], result['uri']\n",
    "    # else return 'No results', 'No results'\n",
    "    threshold = 3\n",
    "\n",
    "    for result in results_list:\n",
    "        distance = Levenshtein.distance(entity, result['name']) # Levenshtein NameError: name 'Levenshtein' is not defined\n",
    "        if distance < threshold:\n",
    "            return result['ui'], result['uri']\n",
    "\n",
    "    return 'No results', 'No results'\n",
    "\n",
    "\n",
    "# function use search_umls to return (term, ui, uri)\n",
    "def process_entity_response(entity, response):\n",
    "    if response and 'result' in response and 'results' in response['result']:        \n",
    "        results_list = response['result']['results']\n",
    "\n",
    "        if results_list:\n",
    "\n",
    "            ui, uri = best_match(entity, results_list)\n",
    "\n",
    "            return entity, ui, uri\n",
    "        else:\n",
    "            return entity, 'No results', 'No results'\n",
    "\n",
    "    else:\n",
    "        return entity, 'Query failed', 'Query failed'\n",
    "\n",
    "# Example usage:\n",
    "# 设置API密钥和基础URL\n",
    "API_KEY = \"751b12fd-192a-4a6d-985d-9b094c99d3c8\"\n",
    "BASE_URL = \"https://uts-ws.nlm.nih.gov/rest\"\n",
    "\n",
    "entity = 'Lungs'\n",
    "\n",
    "response = search_umls_api(entity)\n",
    "# pprint(response)\n",
    "\n",
    "term, ui, uri = process_entity_response(entity, response)\n",
    "print(term, ui, uri)\n",
    "\n",
    "\n",
    "# 'https://uts-ws.nlm.nih.gov/rest/content/2024AA/CUI/C3825187'\n",
    "# return json\n",
    "def umls_api(url):\n",
    "    # url could be 'No results', 'NONE'\n",
    "    if url == 'No results' or url == 'NONE':\n",
    "        return 'No results'\n",
    "\n",
    "    params = {\n",
    "        \"apiKey\": API_KEY\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"查询失败: {term}, 状态码: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# fuction to process response of umls_api() to return (semanticTypes, definition, rootSource)\n",
    "def search_term_def(response):\n",
    "    # url could be 'No results', 'Query failed'\n",
    "    if response == 'No results' or response == 'NONE' or response == 'Query failed':\n",
    "        return 'No results', 'No results', 'No results'\n",
    "\n",
    "    if 'result' not in response:\n",
    "        return 'No results', 'No results', 'No results'\n",
    "\n",
    "    # print(data)\n",
    "    semanticTypes = response['result']['semanticTypes'][0]['name']\n",
    "    definitions_url = response['result']['definitions']\n",
    "\n",
    "\n",
    "    data = umls_api(definitions_url)\n",
    "    # print(data)\n",
    "\n",
    "    if data == 'No results':\n",
    "        return 'No results', 'No results', 'No results'\n",
    "\n",
    "    if data and 'result' in data:\n",
    "        results_list = data['result']\n",
    "\n",
    "        if results_list:\n",
    "\n",
    "            # choose the first definition\n",
    "            best_match = results_list[0]\n",
    "            \n",
    "            return semanticTypes, best_match['value'], best_match['rootSource']\n",
    "        else:\n",
    "            return 'No results', 'No results', 'No results'\n",
    "    else:\n",
    "        return 'No results', 'No results', 'No results'\n",
    "# Example usage:\n",
    "\n",
    "pprint(search_term_def(umls_api(uri)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-the-box Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UMLS': {'definition': {'definition': 'Lobular organ the parenchyma of which '\n",
      "                                       'consists of air-filled alveoli which '\n",
      "                                       'communicate with the tracheobronchial '\n",
      "                                       'tree. Examples: There are only two '\n",
      "                                       'instances, right lung and left lung.',\n",
      "                         'source': 'UWDA'},\n",
      "          'name': 'Lungs',\n",
      "          'semanticTypes': 'Body Part, Organ, or Organ Component',\n",
      "          'ui': 'C0024109'}}\n"
     ]
    }
   ],
   "source": [
    "# return dic of result\n",
    "def nomralize_entity_with_umls(entity):\n",
    "    # Search UMLS with entity    \n",
    "    term, ui, uri = process_entity_response(entity, search_umls_api(entity))\n",
    "\n",
    "    # Process term definition\n",
    "    semanticTypes, definition, source = search_term_def(umls_api(uri))\n",
    "\n",
    "    # Create normalization dictionary\n",
    "    normalization = {\n",
    "        \"UMLS\": {\n",
    "            'ui': ui,\n",
    "            'name': term,\n",
    "            'semanticTypes': semanticTypes,\n",
    "            'definition': {\n",
    "                'definition': definition,\n",
    "                'source': source\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Set normalization if no results found\n",
    "    if ui != 'No results':\n",
    "        entity_value['normalization'] = normalization\n",
    "    \n",
    "    return normalization\n",
    "\n",
    "# Example usage:\n",
    "result = nomralize_entity_with_umls(\"Lungs\")\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Programm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已保存到 '../resource/all_unique_entities_normalized.json 文件中。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pprint\n",
    "\n",
    "# Specify the file path\n",
    "file_path = '../resource/all_unique_entities.json'\n",
    "\n",
    "# Read the JSON file\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    all_entities = json.load(f)\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "# newEntity = {}\n",
    "# i = 0\n",
    "\n",
    "# 遍历顶层字典中的所有项目\n",
    "for entity, entity_value in all_entities.items():\n",
    "\n",
    "    normalization = nomralize_entity_with_umls(entity)\n",
    "\n",
    "    if normalization['UMLS']['ui'] != 'No results':\n",
    "        # set value['normalization']\n",
    "        entity_value['normalization'] = normalization\n",
    "\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # newEntity[entity] = entity_value\n",
    "    # i += 1\n",
    "    # if i > 5:\n",
    "    #     break\n",
    "    \n",
    "\n",
    "# 保存新的 newEntity 数据\n",
    "with open('../resource/all_unique_entities_normalized.json', 'w') as f:\n",
    "    json.dump(all_entities, f, indent=2)\n",
    "\n",
    "print(\"数据已保存到 '../resource/all_unique_entities_normalized.json 文件中。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkgc",
   "language": "python",
   "name": "medkgc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
