{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add report to output for better validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p18/p18001816/s54309228.txt': {'start_ix': 38, 'end_ix': 38, 'text': 'FINAL REPORT INDICATION : Chest pain , dyspnea . COMPARISON : None available . FINDINGS : Chest , PA and lateral . Lung volumes are low . The hilar and cardiomediastinal contours are within normal limits . No chf , focal infiltrate , effusion or pneumothorax is detected . IMPRESSION : No acute pulmonary process identified .'}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "path = '../resource/normalized_entities_gpt_103.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "path = '../../resource/all_unique_entities.json'\n",
    "entities = json.load(open(path))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    # find report for each entity from the reports\n",
    "    entity_name = row['name']\n",
    "    row['report'] = entities[entity_name]['reports'][0]\n",
    "\n",
    "    print(row['report'])\n",
    "    break\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count data[ui] is nan:  364\n",
      "count data[ui] is nan:  364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('output.xlsx')\n",
    "\n",
    "\n",
    "# data2['name'] = data['name']\n",
    "\n",
    "# data2.to_excel('reviewed.xlsx', index=False)\n",
    "\n",
    "# count data[ui] is nan\n",
    "count = 0\n",
    "for i in range(len(data)):\n",
    "    if pd.isna(data['ui'][i]):\n",
    "        count += 1\n",
    "\n",
    "\n",
    "print(\"count data[ui] is nan: \", count)\n",
    "\n",
    "data2 = pd.read_excel('reviewed.xlsx')\n",
    "count = 0\n",
    "for i in range(len(data)):\n",
    "    if pd.isna(data['ui'][i]):\n",
    "        count += 1\n",
    "\n",
    "\n",
    "print(\"count data[ui] is nan: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24 data Pulmonary 'ui' is C0024109, and data_reviewed 'ui' is C2709248\n",
      " 63 data little'ui' is C1440917, but data_reviewed 'ui' is NaN\n",
      " 97 data cardiac 'ui' is C0018787, and data_reviewed 'ui' is C1522601\n",
      " 241 data Cardiac 'ui' is C0018787, and data_reviewed 'ui' is C1522601\n",
      " 449 data severity 'ui' is C0521117, and data_reviewed 'ui' is C0439793 \n",
      " 478 data worrisome 'ui' is C0233481, and data_reviewed 'ui' is C5447511 \n",
      " 480 data constant 'ui' is C1547014, and data_reviewed 'ui' is C1948059 \n",
      " 502 data OPACITIES 'ui' is C1265876, and data_reviewed 'ui' is C0029053\n",
      " 766 data internal jugular central venous 'ui' is C0398279, and data_reviewed 'ui' is C2202213\n",
      " 840 data ARDS 'ui' is C0035222, and data_reviewed 'ui' is C2887484 \n",
      " 871 data Little'ui' is C0023882, but data_reviewed 'ui' is NaN\n",
      " 883 data cardiomegally 'ui' is C0007226, and data_reviewed 'ui' is C0018800 \n",
      " 959 data mm 'ui' is C0456680, and data_reviewed 'ui' is C0439200\n",
      " 983 data Opacity 'ui' is C1265876, and data_reviewed 'ui' is C0029053\n",
      " 985 data bulging 'ui' is C0333056, and data_reviewed 'ui' is C0038999 \n",
      " 1053 data PULMONARY 'ui' is C0024109, and data_reviewed 'ui' is C2709248\n",
      "Total number of rows : 1250\n",
      "Total number of rows was changing: 50\n",
      "Total number of rows na2ui: 34\n",
      "Total number of rows ui2na: 2\n",
      "Total number of rows ui2ui: 14\n",
      "Total number of rows none: 330\n",
      "Total number of rows same: 870\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('output.xlsx')\n",
    "\n",
    "data_all = pd.read_excel('reviewed.xlsx')\n",
    "\n",
    "total_rows = len(data_all)\n",
    "different_rows = 0\n",
    "na2ui = 0\n",
    "ui2na = 0\n",
    "ui2ui = 0\n",
    "none_rows = 0\n",
    "same_rows = 0\n",
    "\n",
    "for i, row in data_all.iterrows():\n",
    "    # now we use data200\n",
    "    ui1 = data.iloc[i]['ui']\n",
    "    ui2 = row['ui']\n",
    "    \n",
    "    # Check if both values are not NaN and they are different\n",
    "    if not (pd.isna(ui1) and pd.isna(ui2)) and ui1 != ui2:\n",
    "        # print(f\"Row {i} has different 'ui': {row['name']}\")\n",
    "        # print(f\"  data: {ui1}\")\n",
    "        # print(f\"  data_reviewed: {ui2}\")\n",
    "        # print()\n",
    "        different_rows += 1\n",
    "\n",
    "        # Further categorize the differences\n",
    "        if pd.isna(ui1):\n",
    "            # print(f\"  data 'ui' is NaN, but data_reviewed 'ui' is {ui2}\")\n",
    "            na2ui += 1\n",
    "        elif pd.isna(ui2):\n",
    "            # print(f\" {i} data {row['name']}'ui' is {ui1}, but data_reviewed 'ui' is NaN\")\n",
    "            ui2na += 1\n",
    "        else:\n",
    "            print(f\" {i} data {row['name']} 'ui' is {ui1}, and data_reviewed 'ui' is {ui2}\")\n",
    "            ui2ui += 1\n",
    "\n",
    "    # both values are NaN\n",
    "    elif pd.isna(ui1) and pd.isna(ui2):\n",
    "        # print(f\"Row {i} has same 'ui': {row['name']}\")\n",
    "        # print(f\"  data: {ui1}, { data.iloc[i]['name']}\")\n",
    "        # print(f\"  data_reviewed: {ui2}, {row['name']}\")\n",
    "        none_rows += 1\n",
    "\n",
    "    # both values are same\n",
    "    elif ui1 == ui2:\n",
    "        same_rows += 1\n",
    "\n",
    "print(f\"Total number of rows : {total_rows}\")\n",
    "print(f\"Total number of rows was changing: {different_rows}\")\n",
    "print(f\"Total number of rows na2ui: {na2ui}\")\n",
    "print(f\"Total number of rows ui2na: {ui2na}\")\n",
    "print(f\"Total number of rows ui2ui: {ui2ui}\")\n",
    "print(f\"Total number of rows none: {none_rows}\")\n",
    "print(f\"Total number of rows same: {same_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) 方法链接CUI，human标注nan：\n",
    "例子：\n",
    "Row 63: little (data: C1440917, data_reviewed: nan)   \n",
    "Row 871: Little (data: C0023882, data_reviewed: C0700321)   \n",
    "特点：\n",
    "这些词是描述性的或修饰性的，\"little\"\n",
    "方法可能过于积极地为这些词分配了 CUI，而人工标注者可能认为这些词在上下文中不需要特定的医学编码。\n",
    "\n",
    "\n",
    "\n",
    "b) 方法与human标注的CUI不一致：\n",
    "\"Heart\" (Row 17): C0018787 -> C1522601  \n",
    "\"Pulmonary\" (Row 24): C0024109 -> C2709248  \n",
    "\"cardiac\" (Row 97): C0018787 -> C1522601  \n",
    "\"severity\" (Row 449): C0521117 -> C0439793  \n",
    "\"OPACITIES\" (Row 502): C1265876 -> C0029053  \n",
    "\n",
    "特点：\n",
    "\n",
    "解剖学术语（\"Heart\", \"Pulmonary\"）\n",
    "形容词（\"cardiac\"）\n",
    "抽象概念（\"severity\"）\n",
    "医学症状描述（\"OPACITIES\"）\n",
    "\n",
    "这种情况可能反映了UMLS中概念的细微差别，或者人工审核者根据上下文选择了更精确的CUI。\n",
    "\n",
    "\n",
    "\n",
    "c) 方法标注nan，human标注CUI：\n",
    "\n",
    "\"surfaces\" (Row 7): nan -> C0205148  \n",
    "\"positioning\" (Row 50): nan -> C0733755  \n",
    "\"lower\" (Row 134): nan -> C0441994  \n",
    "\"compressive\" (Row 169): nan -> C0376507  \n",
    "\"well\" (Row 181): nan -> C3146287  \n",
    "\n",
    "特点：\n",
    "解剖位置描述（\"surfaces\", \"lower\"）\n",
    "医疗操作相关词（\"positioning\"）\n",
    "症状描述（\"compressive\"）\n",
    "常见词汇在医学上下文中的特殊含义（\"well\"）\n",
    "\n",
    "\n",
    "d)人工标注和方法都是nan的情况（152个例子，列举一些典型的）：\n",
    "\n",
    " in standard position, tips, 3.5 cm, components, \n",
    "  not as well seen on this study, 4 cm above, deeper, 1-2 mm, A, rod, overlies, T 5 through T 9, of T 5 through T 9, intrafissural, 1.5 cm\n",
    " \n",
    "特点：\n",
    "\n",
    "包含了大量的描述性术语和短语，这些可能太具体或上下文相关，难以映射到标准化的医学概念。  \n",
    "许多是解剖位置的描述或医疗设备的位置描述。  \n",
    "有些是相对普通的词，没有什么医学特殊含义。  \n",
    "包含了一些非常具体的测量值（如 \"5 cm above\", \"3.5 cm\"）。  \n",
    "有一些是一般性的描述词（如 \"partially\", \"minimally\", \"essentially\"），在医学上下文中可能有特殊含义，但不易标准化。  \n",
    "包含了一些医学缩写（如 \"AP\", \"IJ\"）和专有名词（如 \"Swan\"）。  \n",
    "有一些复合词或短语（如 \"well - expanded\", \"not well seen\"）可能难以映射到单一的标准化概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('output.xlsx')\n",
    "\n",
    "data2 = pd.read_excel('reviewed.xlsx')\n",
    "\n",
    "# data2['name'] = data['name']\n",
    "\n",
    "# data2.to_excel('reviewed.xlsx', index=False)\n",
    "\n",
    "# check data[name] and data2[name] are same\n",
    "for i, row in data2.iterrows():\n",
    "    if data.iloc[i]['name'] != row['name']:\n",
    "        print(f\"Row {i} has different 'name': {row['name']}\")\n",
    "        print(f\"  data: {data.iloc[i]['name']}\")\n",
    "        print(f\"  data2: {row['name']}\")\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data2 = pd.read_excel('output.xlsx')\n",
    "\n",
    "\n",
    "# write first 3 columns of data2 to .csv\n",
    "data2[['name', 'ui', 'normalized_name']].to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkgc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
