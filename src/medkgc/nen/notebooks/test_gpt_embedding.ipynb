{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Pneumothorax and Pneumothorax is An accumulation of air or gas in the PLEURAL CAVITY, which may occur spontaneously or as a result of trauma or a pathological process. The gas may also be introduced deliberately during PNEUMOTHORAX, ARTIFICIAL. (MSH) is 0.9123316407203674\n",
      "Similarity between Pneumothorax and Lungs is Either of the pair of organs occupying the cavity of the thorax that effect the aeration of the blood. (MSH) is 0.835702657699585\n",
      "Similarity between Pneumothorax and Pleural is Of or pertaining to the pleura. (NCI) is 0.8355947136878967\n",
      "Similarity between Pneumothorax and Thyroidectomy is Surgical removal of the thyroid gland. is 0.7639389634132385\n"
     ]
    }
   ],
   "source": [
    "item1 = \"Pneumothorax is An accumulation of air or gas in the PLEURAL CAVITY, which may occur spontaneously or as a result of trauma or a pathological process. The gas may also be introduced deliberately during PNEUMOTHORAX, ARTIFICIAL. (MSH)\"\n",
    "item2 = \"Lungs is Either of the pair of organs occupying the cavity of the thorax that effect the aeration of the blood. (MSH)\"\n",
    "item3 = \"Pleural is Of or pertaining to the pleura. (NCI)\"\n",
    "item4 = \"Thyroidectomy is Surgical removal of the thyroid gland.\" \n",
    "items = [item1, item2, item3, item4]\n",
    "\n",
    "mention = 'Pneumothorax'\n",
    "\n",
    "item_embeddings = [get_embedding(item) for item in items]\n",
    "\n",
    "mention = 'Pneumothorax'\n",
    "mention_embedding = get_embedding(mention)\n",
    "\n",
    "import torch\n",
    "\n",
    "item_embeddings = torch.tensor(item_embeddings)\n",
    "mention_embedding = torch.tensor(mention_embedding)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "for i, item in enumerate(items):\n",
    "    similarity = F.cosine_similarity(mention_embedding.unsqueeze(0), item_embeddings[i].unsqueeze(0))\n",
    "    print(f\"Similarity between {mention} and {item} is {similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mitem_embeddings\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(item_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6b0058ca0f4a4e971cf03db943aa77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "item = 'test'\n",
    "\n",
    "pipeline = pipeline('feature-extraction', model=\"meta-llama/Meta-Llama-3-8B\")\n",
    "data = pipeline(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb892c948d624d3db04b763d0f4411a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efc2cea370b4811b0d9f9cf118f24a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853956c91515446ea9de38d6c6e118e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adae18adc7e4a87bf970f368806448d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959910c63c0645f28c10a31b9b99916a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Cosine Similarity:\n",
      "1. Thyroidectomy is Surgical removal of the thyroid g... (Similarity: 1.0000)\n",
      "2. Pleural is Of or pertaining to the pleura. (NCI)... (Similarity: 1.0000)\n",
      "3. Lungs is Either of the pair of organs occupying th... (Similarity: 1.0000)\n",
      "4. Pneumothorax is An accumulation of air or gas in t... (Similarity: 1.0000)\n",
      "\n",
      "Using Euclidean Similarity:\n",
      "1. Thyroidectomy is Surgical removal of the thyroid g... (Similarity: 1.0000)\n",
      "2. Pleural is Of or pertaining to the pleura. (NCI)... (Similarity: 0.9999)\n",
      "3. Lungs is Either of the pair of organs occupying th... (Similarity: 0.9999)\n",
      "4. Pneumothorax is An accumulation of air or gas in t... (Similarity: 0.9999)\n",
      "\n",
      "Using Dot Product:\n",
      "1. Pleural is Of or pertaining to the pleura. (NCI)... (Similarity: 23961.6815)\n",
      "2. Lungs is Either of the pair of organs occupying th... (Similarity: 23961.6815)\n",
      "3. Pneumothorax is An accumulation of air or gas in t... (Similarity: 23961.6815)\n",
      "4. Thyroidectomy is Surgical removal of the thyroid g... (Similarity: 23961.6796)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# 定义使用Llama 3的get_word_centric_embedding函数\n",
    "def get_word_centric_embedding(text, target_word, model_name=\"meta-llama/Meta-Llama-3-8B\"):\n",
    "    # 初始化pipeline\n",
    "    feature_extractor = pipeline('feature-extraction', model=model_name)\n",
    "    \n",
    "    # 获取整个文本的embedding\n",
    "    full_embedding = feature_extractor(text)\n",
    "    \n",
    "    # 将embedding转换为numpy数组\n",
    "    full_embedding = np.array(full_embedding[0])\n",
    "    \n",
    "    # 获取目标词在文本中的位置\n",
    "    words = text.split()\n",
    "    target_word_positions = [i for i, word in enumerate(words) if word.lower() == target_word.lower()]\n",
    "    \n",
    "    if not target_word_positions:\n",
    "        raise ValueError(f\"Target word '{target_word}' not found in the text.\")\n",
    "    \n",
    "    # 提取目标词的embedding\n",
    "    target_embeddings = full_embedding[target_word_positions]\n",
    "    \n",
    "    # 计算平均embedding\n",
    "    word_centric_embedding = np.mean(target_embeddings, axis=0)\n",
    "    \n",
    "    return word_centric_embedding\n",
    "\n",
    "\n",
    "# 定义项目\n",
    "items = [\n",
    "    \"Pneumothorax is An accumulation of air or gas in the PLEURAL CAVITY, which may occur spontaneously or as a result of trauma or a pathological process. The gas may also be introduced deliberately during PNEUMOTHORAX, ARTIFICIAL. (MSH)\",\n",
    "    \"Lungs is Either of the pair of organs occupying the cavity of the thorax that effect the aeration of the blood. (MSH)\",\n",
    "    \"Pleural is Of or pertaining to the pleura. (NCI)\",\n",
    "    \"Thyroidectomy is Surgical removal of the thyroid gland.\"\n",
    "]\n",
    "\n",
    "mention = \"Pneumothorax\"\n",
    "\n",
    "# 获取每个项目的target word和embedding\n",
    "item_embeddings = []\n",
    "for item in items:\n",
    "    target_word = item.split(' is')[0]\n",
    "    embedding = get_word_centric_embedding(item, target_word)\n",
    "    item_embeddings.append(embedding)\n",
    "\n",
    "# 获取mention的embedding\n",
    "mention_embedding = get_word_centric_embedding(mention, mention)\n",
    "\n",
    "# 定义相似性计算函数\n",
    "def cosine_sim(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]\n",
    "\n",
    "def euclidean_sim(a, b):\n",
    "    return 1 / (1 + euclidean(a, b))\n",
    "\n",
    "def dot_product_sim(a, b):\n",
    "    return np.dot(a, b)\n",
    "\n",
    "# 计算相似性并排序\n",
    "similarity_methods = {\n",
    "    \"Cosine Similarity\": cosine_sim,\n",
    "    \"Euclidean Similarity\": euclidean_sim,\n",
    "    \"Dot Product\": dot_product_sim\n",
    "}\n",
    "\n",
    "for method_name, sim_func in similarity_methods.items():\n",
    "    print(f\"\\nUsing {method_name}:\")\n",
    "    similarities = [sim_func(mention_embedding, item_emb) for item_emb in item_embeddings]\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    \n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        print(f\"{i+1}. {items[idx][:50]}... (Similarity: {similarities[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'Pneumothorax' and 'Pneumothorax is An accumulation of air or gas in the PLEURAL CAVITY, which may occur spontaneously or as a result of trauma or a pathological process. The gas may also be introduced deliberately during PNEUMOTHORAX, ARTIFICIAL. (MSH)' is 0.5690178275108337\n",
      "Similarity between 'Pneumothorax' and 'Lungs is Either of the pair of organs occupying the cavity of the thorax that effect the aeration of the blood. (MSH)' is 0.9573487043380737\n",
      "Similarity between 'Pneumothorax' and 'Pleural is Of or pertaining to the pleura. (NCI)' is 0.988681972026825\n",
      "Similarity between 'Pneumothorax' and 'Thyroidectomy is Surgical removal of the thyroid gland.' is 0.9960650205612183\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Define the mention and items\n",
    "mention = 'Pneumothorax'\n",
    "items = ['Pneumothorax is An accumulation of air or gas in the PLEURAL CAVITY, which may occur spontaneously or as a result of trauma or a pathological process. The gas may also be introduced deliberately during PNEUMOTHORAX, ARTIFICIAL. (MSH)',\n",
    "         'Lungs is Either of the pair of organs occupying the cavity of the thorax that effect the aeration of the blood. (MSH)',\n",
    "         'Pleural is Of or pertaining to the pleura. (NCI)',\n",
    "         'Thyroidectomy is Surgical removal of the thyroid gland.']\n",
    "\n",
    "# Tokenize the mention and items\n",
    "mention_tokens = tokenizer.tokenize(mention)\n",
    "item_tokens = [tokenizer.tokenize(item) for item in items]\n",
    "\n",
    "# Convert tokens to input IDs\n",
    "mention_input_ids = tokenizer.convert_tokens_to_ids(mention_tokens)\n",
    "item_input_ids = [tokenizer.convert_tokens_to_ids(tokens) for tokens in item_tokens]\n",
    "\n",
    "# Pad input IDs to the same length\n",
    "max_length = max(len(mention_input_ids), max(len(ids) for ids in item_input_ids))\n",
    "mention_input_ids = mention_input_ids + [0] * (max_length - len(mention_input_ids))\n",
    "item_input_ids = [ids + [0] * (max_length - len(ids)) for ids in item_input_ids]\n",
    "\n",
    "# Convert input IDs to tensors\n",
    "mention_input_ids = torch.tensor([mention_input_ids])\n",
    "item_input_ids = torch.tensor(item_input_ids)\n",
    "\n",
    "# Generate BERT embeddings\n",
    "with torch.no_grad():\n",
    "    mention_embeddings = model.embeddings.word_embeddings(mention_input_ids)\n",
    "    item_embeddings = model.embeddings.word_embeddings(item_input_ids)\n",
    "\n",
    "# Average the embeddings\n",
    "mention_embedding = mention_embeddings.mean(dim=1)\n",
    "item_embeddings = item_embeddings.mean(dim=1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = [1 - cosine(mention_embedding.squeeze().numpy(), item_embedding.squeeze().numpy()) for item_embedding in item_embeddings]\n",
    "\n",
    "# Print the similarities\n",
    "for i, item in enumerate(items):\n",
    "    print(f\"Similarity between '{mention}' and '{item}' is {similarities[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medkgc",
   "language": "python",
   "name": "medkgc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
